{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEJUlcmKovmJRD/tQspKFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kategimranova/Cinderella_Telegram/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import f1_score\n",
        "import os\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TokPrxWURr1Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_solution = pd.read_csv(\"train_solution.csv\")\n",
        "train_data = pd.read_csv(\"train_data.csv\")"
      ],
      "metadata": {
        "id": "7VO2F-dxR5PC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train_data.merge(train_solution, on='id')"
      ],
      "metadata": {
        "id": "a6pD_z2WSEcm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0QP4aUI7PQgR",
        "outputId": "90f83afc-814e-40dc-8767-b31eaf7bb62f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                            message  category\n",
              "0  271828  Over $616 million in Bitcoin was electrocated ...         1\n",
              "1  271829                          Quiz: Thursday or friday?         0\n",
              "2  271830  The Australian Revenue Authority will start co...         1\n",
              "3  271831   Let's continueüòâ. I present to you my new review          2\n",
              "4  271832                    Here comes your future palette.         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e4bb735-2665-4360-b7ae-0402bd6647f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>message</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>271828</td>\n",
              "      <td>Over $616 million in Bitcoin was electrocated ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>271829</td>\n",
              "      <td>Quiz: Thursday or friday?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>271830</td>\n",
              "      <td>The Australian Revenue Authority will start co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>271831</td>\n",
              "      <td>Let's continueüòâ. I present to you my new review</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>271832</td>\n",
              "      <td>Here comes your future palette.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e4bb735-2665-4360-b7ae-0402bd6647f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e4bb735-2665-4360-b7ae-0402bd6647f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e4bb735-2665-4360-b7ae-0402bd6647f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(train['message']) #—Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"
      ],
      "metadata": {
        "id": "hfjwviv0CnyG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#–æ—Ü–µ–Ω–∫–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤\n",
        "print(train[train.category == 0].shape[0])\n",
        "print(train[train.category == 1].shape[0])\n",
        "print(train[train.category == 2].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jx1MMCvVVrO",
        "outputId": "eb9949a0-8a54-4479-f8c4-05ce82c3411f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1428\n",
            "1199\n",
            "1217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#–§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤. –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞, —á–∏—Å–ª–∞ –º–µ–Ω—è–µ—Ç –Ω–∞ —Ä–µ—à–µ—Ç–∫–∏\n",
        "# –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µc—Ç–≤–∞ —Ü–∏—Ñ—Ä –∏ –ú–µ–Ω—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è (contraction_dict)\n",
        "\n",
        "def clean_text(x):\n",
        "    x = x.lower()\n",
        "    x = replace_contractions(x)\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    x = re.sub(pattern, '', x)\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x\n",
        "\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)"
      ],
      "metadata": {
        "id": "5e7-OyUIEu_B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['cleaned'] = train['message'].apply(lambda x: clean_text(x))"
      ],
      "metadata": {
        "id": "qE5BniKpHYjB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for text in train['cleaned']:\n",
        "  words += text.split()"
      ],
      "metadata": {
        "id": "Nt6GN5HLJwAK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = len(set(words)) #–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤\n",
        "max_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyn0c-ZcSeag",
        "outputId": "ee65ffb8-2c3c-4cda-a8c2-3352dcf913f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16958"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "-xrnCippIm9_",
        "outputId": "4c8b76e8-2f73-4e0e-a0db-8a54d394954c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                            message  category  \\\n",
              "0  271828  Over $616 million in Bitcoin was electrocated ...         1   \n",
              "1  271829                          Quiz: Thursday or friday?         0   \n",
              "2  271830  The Australian Revenue Authority will start co...         1   \n",
              "3  271831   Let's continueüòâ. I present to you my new review          2   \n",
              "4  271832                    Here comes your future palette.         2   \n",
              "\n",
              "                                             cleaned  \n",
              "0  over ### million in bitcoin was electrocated i...  \n",
              "1                            quiz thursday or friday  \n",
              "2  the australian revenue authority will start co...  \n",
              "3    let us continue i present to you my new review   \n",
              "4                     here comes your future palette  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e29421cc-9649-4fa9-86e2-998580375baa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>message</th>\n",
              "      <th>category</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>271828</td>\n",
              "      <td>Over $616 million in Bitcoin was electrocated ...</td>\n",
              "      <td>1</td>\n",
              "      <td>over ### million in bitcoin was electrocated i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>271829</td>\n",
              "      <td>Quiz: Thursday or friday?</td>\n",
              "      <td>0</td>\n",
              "      <td>quiz thursday or friday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>271830</td>\n",
              "      <td>The Australian Revenue Authority will start co...</td>\n",
              "      <td>1</td>\n",
              "      <td>the australian revenue authority will start co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>271831</td>\n",
              "      <td>Let's continueüòâ. I present to you my new review</td>\n",
              "      <td>2</td>\n",
              "      <td>let us continue i present to you my new review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>271832</td>\n",
              "      <td>Here comes your future palette.</td>\n",
              "      <td>2</td>\n",
              "      <td>here comes your future palette</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e29421cc-9649-4fa9-86e2-998580375baa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e29421cc-9649-4fa9-86e2-998580375baa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e29421cc-9649-4fa9-86e2-998580375baa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç (–≤–∞–ª–∏–¥–∞—Ü–∏—é) —Å —É—á–µ—Ç–æ–º –±–∞–ª–∞–Ω—Å–æ–≤ –∫–ª–∞—Å—Å–∞ (stratify) –∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä—ç–Ω–¥–æ–º —Å—Ç–µ–π—Ç–æ–º\n",
        "train_X, test_X, train_y, test_y = train_test_split(train['cleaned'], train['category'],\n",
        "                                                    stratify=train['category'], \n",
        "                                                    test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "CeXlpmvCMB8a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape : \",train_X.shape)\n",
        "print(\"Test shape : \",test_X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL1ROusJMLiT",
        "outputId": "ab720ea1-fb9c-4fe8-aeb1-21ce369f8e20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape :  (2883,)\n",
            "Test shape :  (961,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['len'] = train['cleaned'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "Y1rtm8g6MpJK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#–û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–æ–≤\n",
        "maxlen  = train['len'].max()"
      ],
      "metadata": {
        "id": "yGmnLVr1OrSd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —Å–ª–æ–≤–∞–º \n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(train_X))\n",
        "train_X = tokenizer.texts_to_sequences(train_X)\n",
        "test_X = tokenizer.texts_to_sequences(test_X)"
      ],
      "metadata": {
        "id": "WAatQP2NPi82"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞–¥–¥–∏–Ω–≥–æ–≤ (—á—Ç–æ–±—ã –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –±—ã–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã)\n",
        "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
        "test_X = pad_sequences(test_X, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "zOY_DBq4PIHA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_y = le.fit_transform(train_y.values)\n",
        "test_y = le.transform(test_y.values)"
      ],
      "metadata": {
        "id": "4NAK6teDPwt-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 300 #—Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
      ],
      "metadata": {
        "id": "xBqizqCgCHDO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Text, self).__init__()\n",
        "        filter_sizes = [1,2,3,5]\n",
        "        num_filters = 36\n",
        "        n_classes = 3\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
        "        self.dropout = nn.Dropout(0.15)\n",
        "        self.fc1 = nn.Linear(len(filter_sizes)*num_filters, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  \n",
        "        x = x.unsqueeze(1)  \n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  \n",
        "        logit = self.fc1(x) \n",
        "        return logit"
      ],
      "metadata": {
        "id": "sy8GxgdPqJuZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 13\n",
        "batch_size = 512\n",
        "n_splits = 5\n",
        "model = CNN_Text()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "model.cuda()\n",
        "x_train = torch.tensor(train_X, dtype=torch.long).cuda()\n",
        "y_train = torch.tensor(train_y, dtype=torch.long).cuda()\n",
        "x_cv = torch.tensor(test_X, dtype=torch.long).cuda()\n",
        "y_cv = torch.tensor(test_y, dtype=torch.long).cuda()\n",
        "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    avg_loss = 0.  \n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        y_pred = model(x_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "    \n",
        "    model.eval()        \n",
        "    avg_val_loss = 0.\n",
        "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "    \n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "        val_preds[i * batch_size:(i+1) * batch_size] =F.softmax(y_pred).cpu().numpy()\n",
        "    \n",
        "    val_accuracy = sum(val_preds.argmax(axis=1)==test_y)/len(test_y)\n",
        "    train_loss.append(avg_loss)\n",
        "    valid_loss.append(avg_val_loss)\n",
        "    elapsed_time = time.time() - start_time \n",
        "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
      ],
      "metadata": {
        "id": "lXCu33G4quXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd3c730-dc84-4983-daf3-505a2294ca24"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13 \t loss=457.3944 \t val_loss=321.1057  \t val_acc=0.7534  \t time=10.56s\n",
            "Epoch 2/13 \t loss=314.3801 \t val_loss=275.7043  \t val_acc=0.7836  \t time=10.49s\n",
            "Epoch 3/13 \t loss=262.1659 \t val_loss=248.3005  \t val_acc=0.8002  \t time=10.57s\n",
            "Epoch 4/13 \t loss=218.0238 \t val_loss=227.6057  \t val_acc=0.8314  \t time=10.63s\n",
            "Epoch 5/13 \t loss=188.5969 \t val_loss=216.1898  \t val_acc=0.8273  \t time=10.64s\n",
            "Epoch 6/13 \t loss=169.2611 \t val_loss=206.5979  \t val_acc=0.8439  \t time=10.68s\n",
            "Epoch 7/13 \t loss=144.8870 \t val_loss=199.8827  \t val_acc=0.8491  \t time=10.71s\n",
            "Epoch 8/13 \t loss=128.1963 \t val_loss=193.8829  \t val_acc=0.8564  \t time=10.83s\n",
            "Epoch 9/13 \t loss=111.2685 \t val_loss=190.0008  \t val_acc=0.8606  \t time=10.76s\n",
            "Epoch 10/13 \t loss=98.8440 \t val_loss=185.4957  \t val_acc=0.8595  \t time=10.80s\n",
            "Epoch 11/13 \t loss=86.8472 \t val_loss=183.7496  \t val_acc=0.8626  \t time=10.85s\n",
            "Epoch 12/13 \t loss=77.4107 \t val_loss=181.6650  \t val_acc=0.8647  \t time=10.88s\n",
            "Epoch 13/13 \t loss=67.1676 \t val_loss=179.0017  \t val_acc=0.8658  \t time=10.91s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model_new1.pt\")"
      ],
      "metadata": {
        "id": "0pyN_TgjwSM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}